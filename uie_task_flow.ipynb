{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "uie_task_flow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWornuOp5a2tYDhr/P/QlZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxs131/IE/blob/main/uie_task_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CCKS统一信息抽取模型比赛\n",
        "\n",
        "这里为了方便还是就用百度提出的uie-char-small，一会看看有没有好点模型，然后uie-char-small模型上训练策略修改修改，实在不行就分别弄了\n",
        "\n",
        "uie官网地址:"
      ],
      "metadata": {
        "id": "4gKy3F5Eug_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bj6LOWdCrJq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199ef054-60ed-404a-edf3-037dd69397c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlepaddle\n",
            "  Downloading paddlepaddle-2.3.0-cp37-cp37m-manylinux1_x86_64.whl (112.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 112.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Collecting paddle-bfloat==0.1.2\n",
            "  Downloading paddle_bfloat-0.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (373 kB)\n",
            "\u001b[K     |████████████████████████████████| 373 kB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (2.23.0)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n",
            "Installing collected packages: paddle-bfloat, paddlepaddle\n",
            "Successfully installed paddle-bfloat-0.1.2 paddlepaddle-2.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlenlp\n",
            "  Downloading paddlenlp-2.3.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 23.4 MB/s \n",
            "\u001b[?25hCollecting multiprocess<=0.70.12.2\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 70.7 MB/s \n",
            "\u001b[?25hCollecting datasets>=2.0.0\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlenlp) (3.17.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 64.6 MB/s \n",
            "\u001b[?25hCollecting paddlefsl\n",
            "  Downloading paddlefsl-1.1.0-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from paddlenlp) (0.42.1)\n",
            "Collecting paddle2onnx\n",
            "  Downloading paddle2onnx-0.9.8-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddlenlp) (4.64.0)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->paddlenlp) (4.11.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 75.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->paddlenlp) (21.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->paddlenlp) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->paddlenlp) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->paddlenlp) (1.3.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->paddlenlp) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.0,>=3.1.0->paddlenlp) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=2.0.0->paddlenlp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=2.0.0->paddlenlp) (2022.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->paddlenlp) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=d20d75a0563ac32fc26381bac9b98a35cda8db68d866eaa8f46495c8acd2caf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, dill, aiohttp, xxhash, responses, multiprocess, huggingface-hub, seqeval, sentencepiece, paddlefsl, paddle2onnx, datasets, colorlog, colorama, paddlenlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 colorama-0.4.5 colorlog-6.6.0 datasets-2.3.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 multiprocess-0.70.12.2 paddle2onnx-0.9.8 paddlefsl-1.1.0 paddlenlp-2.3.4 pyyaml-6.0 responses-0.18.0 sentencepiece-0.1.96 seqeval-1.2.2 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlepaddle\n",
        "!pip install paddlenlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##尝试UIE taskflow\n",
        "\n",
        "简单尝试一下效果"
      ],
      "metadata": {
        "id": "FR3d-GDe4U6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from paddlenlp import Taskflow\n",
        "\n",
        "schema=['时间','选手','选手姓名']\n",
        "\n",
        "ie=Taskflow('information_extraction',schema=schema)\n",
        "result=ie('2022年7月2日上午北京冬奥会自由式滑雪女子大跳台决赛中中国选手谷爱凌以188.25分获得金牌！')\n",
        "pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaPRkgdX4Zbk",
        "outputId": "8da267e7-f891-4765-f9aa-3e796e466347"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n",
            "  from numpy.dual import register_func\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "\u001b[32m[2022-07-02 07:44:42,970] [    INFO]\u001b[0m - Downloading model_state.pdparams from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_v1.0/model_state.pdparams\u001b[0m\n",
            "100%|██████████| 450M/450M [00:21<00:00, 21.8MB/s]\n",
            "\u001b[32m[2022-07-02 07:45:06,202] [    INFO]\u001b[0m - Downloading model_config.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/model_config.json\u001b[0m\n",
            "100%|██████████| 377/377 [00:00<00:00, 145kB/s]\n",
            "\u001b[32m[2022-07-02 07:45:06,595] [    INFO]\u001b[0m - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/vocab.txt\u001b[0m\n",
            "100%|██████████| 182k/182k [00:03<00:00, 61.4kB/s]\n",
            "\u001b[32m[2022-07-02 07:45:10,158] [    INFO]\u001b[0m - Downloading special_tokens_map.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/special_tokens_map.json\u001b[0m\n",
            "100%|██████████| 112/112 [00:00<00:00, 55.2kB/s]\n",
            "\u001b[32m[2022-07-02 07:45:10,553] [    INFO]\u001b[0m - Downloading tokenizer_config.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/tokenizer_config.json\u001b[0m\n",
            "100%|██████████| 172/172 [00:00<00:00, 101kB/s]\n",
            "\u001b[32m[2022-07-02 07:45:10,981] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/root/.paddlenlp/taskflow/information_extraction/uie-base'.\u001b[0m\n",
            "\u001b[32m[2022-07-02 07:45:19,900] [    INFO]\u001b[0m - Converting to the inference model cost a little time.\u001b[0m\n",
            "\u001b[32m[2022-07-02 07:45:26,086] [    INFO]\u001b[0m - The inference model save in the path:/root/.paddlenlp/taskflow/information_extraction/uie-base/static/inference\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'时间': [{'end': 11,\n",
            "          'probability': 0.9582728895798596,\n",
            "          'start': 0,\n",
            "          'text': '2022年7月2日上午'}],\n",
            "  '选手': [{'end': 36,\n",
            "          'probability': 0.9260867261951482,\n",
            "          'start': 33,\n",
            "          'text': '谷爱凌'}],\n",
            "  '选手姓名': [{'end': 36,\n",
            "            'probability': 0.9916217407515582,\n",
            "            'start': 33,\n",
            "            'text': '谷爱凌'}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema=['宗门','世界','主角','家乡']\n",
        "\n",
        "ie=Taskflow('information_extraction',schema=schema)\n",
        "result=ie('唐门外门弟子唐三，因偷学内门绝学为唐门所不容，跳崖明志时却发现没有死，反而以另外一个身份来到了另一个世界，一个属于武魂的世界，名叫斗罗大陆。这里没有魔法，没有斗气，没有武术，却有神奇的武魂。这里的每个人，在自己六岁的时候，都会在武魂殿中令武魂觉醒。武魂有动物，有植物，有器物，武魂可以辅助人们的日常生活。而其中一些特别出色的武魂却可以用来修炼并进行战斗，这个职业，是斗罗大陆上最为强大也是最荣耀的职业“魂师”。 小小的唐三在圣魂村开始了他的魂师修炼之路，并萌生了振兴唐门的梦想。当唐门暗器来到斗罗大陆，当唐三武魂觉醒，他能否在这片武魂的世界再铸唐门的辉煌？')\n",
        "pprint(result)"
      ],
      "metadata": {
        "id": "OZ6DlVrd3q43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##关系抽取"
      ],
      "metadata": {
        "id": "lHGlUzG_3pWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema= {'学习': ['人物', '地点', '学习内容']} \n",
        "\n",
        "ie=Taskflow('information_extraction',schema=schema)\n",
        "result=ie('唐门外门弟子唐三，因偷学内门绝学为唐门所不容，跳崖明志时却发现没有死，反而以另外一个身份来到了另一个世界，一个属于武魂的世界，名叫斗罗大陆。这里没有魔法，没有斗气，没有武术，却有神奇的武魂。这里的每个人，在自己六岁的时候，都会在武魂殿中令武魂觉醒。武魂有动物，有植物，有器物，武魂可以辅助人们的日常生活。而其中一些特别出色的武魂却可以用来修炼并进行战斗，这个职业，是斗罗大陆上最为强大也是最荣耀的职业“魂师”。 小小的唐三在圣魂村开始了他的魂师修炼之路，并萌生了振兴唐门的梦想。当唐门暗器来到斗罗大陆，当唐三武魂觉醒，他能否在这片武魂的世界再铸唐门的辉煌？')\n",
        "pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzdC9w4n5uDs",
        "outputId": "a46c49c4-efae-4ea3-d136-cbaf67cd341e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2022-07-02 07:47:15,955] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/root/.paddlenlp/taskflow/information_extraction/uie-base'.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'学习': [{'end': 16,\n",
            "          'probability': 0.7883434448981035,\n",
            "          'relations': {'人物': [{'end': 8,\n",
            "                                'probability': 0.9901956775776135,\n",
            "                                'start': 6,\n",
            "                                'text': '唐三'}],\n",
            "                        '地点': [{'end': 69,\n",
            "                                'probability': 0.3184169048552121,\n",
            "                                'start': 65,\n",
            "                                'text': '斗罗大陆'}]},\n",
            "          'start': 12,\n",
            "          'text': '内门绝学'}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##情感抽取"
      ],
      "metadata": {
        "id": "RzLMtUOB4m_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {'评价维度': ['观点词', '情感倾向[正向，负向]']}\n",
        "ie.set_schema(schema) # Reset schema\n",
        "\n",
        "pprint(ie(\"店面干净，很清静，服务员服务热情，性价比很高，发现收银台有排队\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmsjqOqx4mns",
        "outputId": "304f0b60-7cc1-4eb3-a8d3-712a4fce930a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'评价维度': [{'end': 20,\n",
            "            'probability': 0.9817038485103247,\n",
            "            'relations': {'情感倾向[正向，负向]': [{'probability': 0.9966141910078932,\n",
            "                                           'text': '正向'}],\n",
            "                          '观点词': [{'end': 22,\n",
            "                                   'probability': 0.9573964135112369,\n",
            "                                   'start': 21,\n",
            "                                   'text': '高'}]},\n",
            "            'start': 17,\n",
            "            'text': '性价比'},\n",
            "           {'end': 2,\n",
            "            'probability': 0.969684604808748,\n",
            "            'relations': {'情感倾向[正向，负向]': [{'probability': 0.9982153274927796,\n",
            "                                           'text': '正向'}],\n",
            "                          '观点词': [{'end': 4,\n",
            "                                   'probability': 0.9945316855823414,\n",
            "                                   'start': 2,\n",
            "                                   'text': '干净'}]},\n",
            "            'start': 0,\n",
            "            'text': '店面'}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {'评价维度': ['观点词', '情感倾向[正向，负向]']}\n",
        "ie.set_schema(schema) # Reset schema\n",
        "\n",
        "pprint(ie(\"陈老师人非常好，做事细心\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UhfVN-55Vbu",
        "outputId": "1423c699-cd54-41d5-c003-9895f725bf04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'评价维度': [{'end': 10,\n",
            "            'probability': 0.40598373906871643,\n",
            "            'relations': {'情感倾向[正向，负向]': [{'probability': 0.9971581224388046,\n",
            "                                           'text': '正向'}],\n",
            "                          '观点词': [{'end': 12,\n",
            "                                   'probability': 0.9882965019443795,\n",
            "                                   'start': 10,\n",
            "                                   'text': '细心'}]},\n",
            "            'start': 8,\n",
            "            'text': '做事'},\n",
            "           {'end': 4,\n",
            "            'probability': 0.7083232855425337,\n",
            "            'relations': {'情感倾向[正向，负向]': [{'probability': 0.9988135028029319,\n",
            "                                           'text': '正向'}],\n",
            "                          '观点词': [{'end': 7,\n",
            "                                   'probability': 0.9879722989214912,\n",
            "                                   'start': 6,\n",
            "                                   'text': '好'}]},\n",
            "            'start': 3,\n",
            "            'text': '人'}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#下载数据"
      ],
      "metadata": {
        "id": "JU9BJe2nshPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#训练集\n",
        "%cd /content/data\n",
        "!wget https://dataset-bj.cdn.bcebos.com/qianyan/duuie.zip\n",
        "!unzip duuie.zip\n",
        "\n",
        "#可见模板\n",
        "!wget https://dataset-bj.cdn.bcebos.com/qianyan/seen_schema.zip\n",
        "!unzip seen_schema.zip\n",
        "\n",
        "#测试集\n",
        "!wget https://dataset-bj.cdn.bcebos.com/qianyan/duuie_test_a.zip\n",
        "!unzip duuie_test_a"
      ],
      "metadata": {
        "id": "mceUjzXuseNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##安装依赖和下载uie的预训练权重"
      ],
      "metadata": {
        "id": "4-fe9erRuz2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/information_extraction/DuUIE.git"
      ],
      "metadata": {
        "id": "hsfCajJa094B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DuUIE\n",
        "!pip install -r requirements.txt \n",
        "!wget https://paddlenlp.bj.bcebos.com/models/ccks2022/uie-char-small.zip && unzip uie-char-small.zip"
      ],
      "metadata": {
        "id": "rjALgR3Qsl47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##数据预处理"
      ],
      "metadata": {
        "id": "AmNpxw8Us_EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DuUIE\n",
        "#设置data路径\n",
        "!python process_data.py preprocess"
      ],
      "metadata": {
        "id": "ZErDe2Y-s-Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用config/multi-task-duuie.yaml配置路径和训练参数，然后进行训练"
      ],
      "metadata": {
        "id": "aYewO-1ItagE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用中文 UIE-char-small 开展多任务模型训练\n",
        "! python3 run_seq2struct.py                              \\\n",
        "  --multi_task_config config/multi-task-duuie.yaml     \\\n",
        "  --negative_keep 1.0                                  \\\n",
        "  --do_train                                           \\\n",
        "  --metric_for_best_model=all-task-ave                 \\\n",
        "  --model_name_or_path=./uie-char-small                \\\n",
        "  --num_train_epochs=2                                \\\n",
        "  --per_device_train_batch_size=32                     \\\n",
        "  --per_device_eval_batch_size=256                     \\\n",
        "  --output_dir=output/duuie_multi_task_b32_lr5e-4      \\\n",
        "  --logging_dir=output/duuie_multi_task_b32_lr5e-4_log \\\n",
        "  --learning_rate=5e-4                                 \\\n",
        "  --overwrite_output_dir                               \\\n",
        "  --gradient_accumulation_steps 1"
      ],
      "metadata": {
        "id": "Y4DWbzpatZmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##进行推理"
      ],
      "metadata": {
        "id": "mEcPKtM7tzpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DuUIE\n",
        "!python process_data.py split-test\n",
        "!python inference.py --data data/duuie_test_a --model output/duuie_multi_task_b32_lr5e-4"
      ],
      "metadata": {
        "id": "I2v7ogRYtzFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##合并为可提交文件"
      ],
      "metadata": {
        "id": "I6U_lETHuAx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 合并预测结果并提交\n",
        "!python process_data.py merge-test"
      ],
      "metadata": {
        "id": "u_Dy7LzmuAKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}